# planar_ising
Code associated with paper: "Classical Models of Entanglement in Monitored Random Circuits" Oles Shtanko, Yaroslav A. Kharkov, Luis Pedro Garc√≠a-Pintos, Alexey V. Gorshkov (2020) arXiv:2004.06736 (now in progress of resubmission)

# Introduction

This code is used to replicate the results of the paper.

## Lattice structure

The structure of Ising triangular lattice generated using the file: /planar_ising/generate_lattice_plot.py

Result is demosntrated below:

Resulting lattices shows different couplings of classical Ising model for a randomly generated measurements, as denoted in this plot. 

The size of the lattice can be changed in the file using parameters Lph (physical length/number of qubits) and Tph (physical time/circuit depth). Program automatically recalculate corresponding lattice dimensions and mark the specific edges. The order of meausurements can also be manually accessed by changing the boolean array "meas".

## Collapse plot

The collapse plot including critical point and critical exponent generated by the file: /planar_ising/generate_collapse_plot.py

The result is demonstrated below:

The size scaling of the order parameter can be used to derive the critical point $p_c$ and the critical exponent $\nu$. The evaluated critical parameters are printed upon running the file. More samples can be generated and stored upon setting the parameter "samples" to any float number. The function "overwrite" resets the data files and starts sampling from the scratch.

## Error plot

The error analysis plot is generated by the file: /planar_ising/generate_precision_plot.py

The result is demonstrated below:

First plot demosntrates how quickly the value of entropy saturates as parameter $\Gamma$ increases in the limit in Eq.() of the main text. The cirucit is take of size N and depth N. The second plot illustrates the decay of the error with encrease of $Gamma$. The dashed line show the asymptoti of exponential error suppresion. The third grapth illustrates the error caused by insufficient digita precision of $\Gamma$. Fro this plot, it follows that the digital precision should increase at least as the number N.



![Figure_1 copy](https://user-images.githubusercontent.com/21160786/56327155-1b4b4200-6147-11e9-8837-694417ae332b.png)

To preserve the distributor's anonymity, we replaced the names of the nodes at Level 2 and below by numbers (for Drinks Level 3 and below) by numbers. We also added lags of sales and prices.  The resulting data set takes the form:

![Screenshot 2019-04-24 18 05 08](https://user-images.githubusercontent.com/21160786/56697127-e9445d80-66bb-11e9-95b6-4fb137841df2.png)



## Code

To replicate the results:

1. Download the github repo 
2. Open Rstudio (or R) and run
`install.packages(c("tictoc","cowplot","xtable","parallel","expm", "foreach", 'gamlr", "glmnet","ggplot2", "dplyr","plyr","reshape2","tidyr","iterators","assertthat","tidyverse","rmutil"))`

### Figure : Own price elasticities for categories as estimated by Orthogonal Least Squares (Double Machine Learning)
3. Open /orthoml-master/src/Figure3.R and set directoryname to the location of downloaded file. From the shell/or in R, run `Figure3.R`. 

The code produces the estimate and 95% confidence interval for the average price elasticity for each category in {Drinks, Dairy, NonEdible, Snacks}. A plot example for Drinks is given below

![BoxDrinksLevel1](https://user-images.githubusercontent.com/21160786/56698512-214d9f80-66c0-11e9-9de9-347947ac58d8.png)

### Figure : Own price elasticities by the months of a calendar year as estimated by  Orthogonal Least Squares (Double Machine Learning)

4. Open /orthoml-master/src/Figure3.R and set directoryname to the location of downloaded file. From the shell/or in R, `Figure4.R`. 

The code produces the estimate and 95% confidence interval for the average price elasticity by calendar month for each category in {Dairy, NonEdible, Snacks, Sodas, Water}. A plot example is given below

![BoxDrinksmonthSodas](https://user-images.githubusercontent.com/21160786/56698599-7f7a8280-66c0-11e9-8023-23353d600cdd.png)

### Figure : Distribution of Own price elasticities as estimated by Orthogonal Lasso, Double Orthogonal Ridge, and Orthogonal Least Squares 

4. Open /orthoml-master/src/Figure3.R and to the location of downloaded file. From the shell/or in R, `Figure5.R`. 

The code produces a histogram of estimates for the average price elasticity for categories, aggregated at Level2, Level 3, Level4, grouped by color at Level1. A plot example is given below

![HistLevel4Dairy](https://user-images.githubusercontent.com/21160786/56698604-81dcdc80-66c0-11e9-8e4c-dab2ab27f100.png)

We see that Lasso estimates are most concenrated (shrinked towards homogenous specification), Orthogonal Least Squares  is most dispersed (and least precise), and  Double Orthogonal Ridge is in the middle. 

# References:

"Double/Debiased Machine Learning for Treatment and Causal Parameters" (Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins), 2017, https://arxiv.org/abs/1608.00060

"Estimation and Inference about Heterogeneous Treatment Effects in High-Dimensional Dynamic Panels"
Vira Semenova, Matt Goldman, Victor Chernozhukov, Matt Taddy, 2017, https://economics.mit.edu/files/15984 

"Pricing Engine: Estimating Causal Impacts in Real World Business Settings" Matt Goldman, Brian Quistorff, 2018, https://arxiv.org/abs/1806.03285 
